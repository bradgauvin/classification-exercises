{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02cd465",
   "metadata": {},
   "source": [
    "### Model exercises\n",
    "Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "5. Run through steps 2-4 using a different max_depth value.\n",
    "6. Which model performs better on your in-sample data?\n",
    "7. Which model performs best on your out-of-sample data, the validate set?\n",
    "8. Work through these same exercises using the Telco dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a02abd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env Set up\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import acquire as acq\n",
    "import prepare as pp\n",
    "# Decision Tree and Model Evaluation Imports\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c45b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached csv\n"
     ]
    }
   ],
   "source": [
    "titanic = acq.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381767f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached csv\n",
      "Data cleaned for duplicates, columns dropped [deck, embarked, class, age], filled na, and added numerical versions of sex and embark\n"
     ]
    }
   ],
   "source": [
    "titanic = pp.prep_titanic(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df991c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7f8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = pp.train_validate_test_split(titanic, target = 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b4125b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 12), (214, 12), (179, 12))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c318a9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is your baseline prediction? \n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bf115ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Baseline accuracy is: 61.65%\n"
     ]
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "train['baseline'] = 0\n",
    "print(f' Baseline accuracy is: {(train.survived==train.baseline).mean():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38470046",
   "metadata": {},
   "source": [
    "1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba80fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 498 entries, 583 to 744\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   passenger_id             498 non-null    int64  \n",
      " 1   survived                 498 non-null    int64  \n",
      " 2   pclass                   498 non-null    int64  \n",
      " 3   sex                      498 non-null    object \n",
      " 4   sibsp                    498 non-null    int64  \n",
      " 5   parch                    498 non-null    int64  \n",
      " 6   fare                     498 non-null    float64\n",
      " 7   embark_town              498 non-null    object \n",
      " 8   alone                    498 non-null    int64  \n",
      " 9   sex_male                 498 non-null    uint8  \n",
      " 10  embark_town_Queenstown   498 non-null    uint8  \n",
      " 11  embark_town_Southampton  498 non-null    uint8  \n",
      " 12  baseline                 498 non-null    int64  \n",
      "dtypes: float64(1), int64(7), object(2), uint8(3)\n",
      "memory usage: 44.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "607ce0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "features = ['pclass', 'embark_town_Queenstown', 'embark_town_Southampton', 'sex_male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364bdac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "x_train = train[features]\n",
    "y_train = train[['survived']]\n",
    "\n",
    "x_validate = validate[features]\n",
    "y_validate = validate[['survived']]\n",
    "\n",
    "x_test = test[features]\n",
    "y_test = test[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d27173a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  embark_town_Queenstown  embark_town_Southampton  sex_male\n",
       "583       1                       0                        0         1\n",
       "165       3                       0                        1         1\n",
       "50        3                       0                        1         1\n",
       "259       2                       0                        1         0\n",
       "306       1                       0                        0         0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37814139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived\n",
       "583         0\n",
       "165         1\n",
       "50          0\n",
       "259         1\n",
       "306         1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3ebf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0           307\n",
       "1           191\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20df700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "900a8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree= tree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c4ae317",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e23a3d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- sex_male <= 0.50\n",
      "|   |--- pclass <= 2.50\n",
      "|   |   |--- embark_town_Southampton <= 0.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- embark_town_Southampton >  0.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- pclass >  2.50\n",
      "|   |   |--- embark_town_Southampton <= 0.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- embark_town_Southampton >  0.50\n",
      "|   |   |   |--- class: 0\n",
      "|--- sex_male >  0.50\n",
      "|   |--- pclass <= 1.50\n",
      "|   |   |--- embark_town_Queenstown <= 0.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- embark_town_Queenstown >  0.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- pclass >  1.50\n",
      "|   |   |--- pclass <= 2.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- pclass >  2.50\n",
      "|   |   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "internet_service_type\n",
    "print(export_text(tree, feature_names=x_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9175787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on training set is: 81.93%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "print(f'Accuracy score on training set is: {tree.score(x_train,y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6e6cac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>294</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  294   13\n",
       "1   77  114"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.survived.unique())\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index = labels, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b94aa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294, 13, 77, 114)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows are truth, columns are pred\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7556464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       307\n",
      "           1       0.90      0.60      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.85      0.78      0.79       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d1ea1",
   "metadata": {},
   "source": [
    "Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30f3854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulas\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp/(tp+fp) \n",
    "recall = tp/(tp+fn)\n",
    "f1 = (2* precision * recall)/(precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0832c959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate: 4.23%\n",
      "False negative rate: 40.31%\n",
      "True positive rate: 59.69%\n",
      "True negative rate: 95.77%\n",
      "Accuracy rate: 81.93%\n",
      "Precision rate: 89.76%\n",
      "Recall rate: 59.69%\n",
      "F1 score:  71.70%\n"
     ]
    }
   ],
   "source": [
    "# Written out answers\n",
    "print(f\"False positive rate: {fp/(fp+tn):.2%}\")\n",
    "print(f\"False negative rate: {fn/(fn+tp):.2%}\")\n",
    "print(f\"True positive rate: {tp/(tp+fn):.2%}\")\n",
    "print(f\"True negative rate: {tn/(fp+tn):.2%}\")\n",
    "print(f\"Accuracy rate: {(tp + tn) / (tp + tn + fp + fn):.2%}\")\n",
    "print(f\"Precision rate: {precision:.2%}\")\n",
    "print(f\"Recall rate: {recall:.2%}\")\n",
    "print(f\"F1 score: {f1: .2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db04db",
   "metadata": {},
   "source": [
    "Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e0413e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(train, d = 5, print_results = True):\n",
    "    \n",
    "    selected_features = ['pclass','embark_town_Queenstown','embark_town_Southampton','sex_male']\n",
    "    X_train = train[selected_features]\n",
    "    y_train = train[['survived']]\n",
    "    ship = DecisionTreeClassifier(max_depth=d, random_state=123)\n",
    "    ship = ship.fit(X_train, y_train)\n",
    "    y_pred = ship.predict(X_train)\n",
    "    if print_results:\n",
    "        print(\"TRAINING RESULTS\")\n",
    "        print(\"----------------\")\n",
    "        print(f\"Accuracy score on training set is: {ship.score(X_train, y_train):.2f}\")\n",
    "        print(classification_report(y_train, y_pred))\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
    "\n",
    "        print(f\"False positive rate: {fp/(fp+tn):.2%}\")\n",
    "        print(f\"False negative rate: {fn/(fn+tp):.2%}\")\n",
    "        print(f\"True positive rate: {tp/(tp+fn):.2%}\")\n",
    "        print(f\"True negative rate: {tn/(fp+tn):.2%}\")\n",
    "        print(\"----------------\")\n",
    "    \n",
    "    return ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cdd4b857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For decision tree with depth3:\n",
      "TRAINING RESULTS\n",
      "----------------\n",
      "Accuracy score on training set is: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       307\n",
      "           1       0.90      0.60      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.85      0.78      0.79       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n",
      "False positive rate: 4.23%\n",
      "False negative rate: 40.31%\n",
      "True positive rate: 59.69%\n",
      "True negative rate: 95.77%\n",
      "----------------\n",
      "For decision tree with depth5:\n",
      "TRAINING RESULTS\n",
      "----------------\n",
      "Accuracy score on training set is: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       307\n",
      "           1       0.90      0.60      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.85      0.78      0.79       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n",
      "False positive rate: 4.23%\n",
      "False negative rate: 40.31%\n",
      "True positive rate: 59.69%\n",
      "True negative rate: 95.77%\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i in[3,5]:\n",
    "    print(f'For decision tree with depth{i}:')\n",
    "    decision_tree(train, d=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0577e",
   "metadata": {},
   "source": [
    "## Which model performs better on your in-sample data?\n",
    "### Takeaway:\n",
    "-  Depth 3 and 5 are identical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d1f15",
   "metadata": {},
   "source": [
    "### Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf08f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_results(d):\n",
    "    ship = decision_tree(train, d = d, print_results = False)\n",
    "    print('')\n",
    "    print(f'For decision tree of depth: {ship.max_depth}')\n",
    "    print('VALIDATE RESULTS')\n",
    "    print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "         .format(ship.score(x_validate, y_validate)))\n",
    "\n",
    "\n",
    "    # Produce y_predictions that come from the X_validate\n",
    "    y_pred = ship.predict(x_validate)\n",
    "\n",
    "    # Compare actual y values (from validate) to predicted y_values from the model run on X_validate\n",
    "    print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8d1ace5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For decision tree of depth: 3\n",
      "VALIDATE RESULTS\n",
      "Accuracy of Decision Tree classifier on validate set: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       132\n",
      "           1       0.88      0.54      0.67        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.82      0.75      0.76       214\n",
      "weighted avg       0.81      0.79      0.78       214\n",
      "\n",
      "\n",
      "For decision tree of depth: 5\n",
      "VALIDATE RESULTS\n",
      "Accuracy of Decision Tree classifier on validate set: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       132\n",
      "           1       0.88      0.54      0.67        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.82      0.75      0.76       214\n",
      "weighted avg       0.81      0.79      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [3,5]:\n",
    "    validate_results(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfda129d",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "- Depth 3 and 5 are identical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0df0e4",
   "metadata": {},
   "source": [
    "### Work through these same exercises using the Telco dataset.\n",
    "- See Telco_modeling notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d49365d",
   "metadata": {},
   "source": [
    "## Exercises Random Forest\n",
    "\n",
    "\n",
    "Continue working in your `model` file with titanic data to do the following: \n",
    "\n",
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "1. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "1. Print and clearly label the following:  Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "1. Run through steps increasing your min_samples_leaf and decreasing your max_depth. \n",
    "\n",
    "1. What are the differences in the evaluation metrics?  Which performs better on your in-sample data?  Why?\n",
    "\n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a035b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached csv\n"
     ]
    }
   ],
   "source": [
    "df=acq.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d52637dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d03aedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns = ['passenger_id', 'deck','embarked','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ac5af75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare  embark_town  alone\n",
       "0         0       3    male  22.0      1      0   7.2500  Southampton      0\n",
       "1         1       1  female  38.0      1      0  71.2833    Cherbourg      0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f6e5b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 9)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe4349de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns = ['embark_town','sex'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc2dc62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 10), (171, 10), (143, 10))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = pp.train_validate_test_split(df, target='survived')\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "906f05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['baseline'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "82cca127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy is: 59.55%\n"
     ]
    }
   ],
   "source": [
    "print(f'Baseline accuracy is: {(train.survived == train.baseline).mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aeaa4db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 398 entries, 450 to 749\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   survived                 398 non-null    int64  \n",
      " 1   pclass                   398 non-null    int64  \n",
      " 2   age                      398 non-null    float64\n",
      " 3   sibsp                    398 non-null    int64  \n",
      " 4   parch                    398 non-null    int64  \n",
      " 5   fare                     398 non-null    float64\n",
      " 6   alone                    398 non-null    int64  \n",
      " 7   embark_town_Queenstown   398 non-null    uint8  \n",
      " 8   embark_town_Southampton  398 non-null    uint8  \n",
      " 9   sex_male                 398 non-null    uint8  \n",
      " 10  baseline                 398 non-null    int64  \n",
      "dtypes: float64(2), int64(6), uint8(3)\n",
      "memory usage: 29.2 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b17b767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pclass','embark_town_Queenstown', 'embark_town_Southampton','sex_male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f0e91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_and_y(train, validate, test, features, target):\n",
    "    x_train = train[features]\n",
    "    y_train = train[target]\n",
    "    \n",
    "    x_validate = validate[features]\n",
    "    y_validate = validate[target]\n",
    "    \n",
    "    x_test = test[features]\n",
    "    y_test = test[target]\n",
    "    \n",
    "    return {'x_train': x_train, 'y_train': y_train, 'x_validate': x_validate, 'y_validate': y_validate, 'x_test': x_test, 'y_test': y_test}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aae8c6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_train':      pclass  embark_town_Queenstown  embark_town_Southampton  sex_male\n",
       " 450       2                       0                        1         1\n",
       " 543       2                       0                        1         1\n",
       " 157       3                       0                        1         1\n",
       " 462       1                       0                        1         1\n",
       " 397       2                       0                        1         1\n",
       " ..      ...                     ...                      ...       ...\n",
       " 820       1                       0                        1         0\n",
       " 673       2                       0                        1         1\n",
       " 310       1                       0                        0         0\n",
       " 72        2                       0                        1         1\n",
       " 749       3                       1                        0         1\n",
       " \n",
       " [398 rows x 4 columns],\n",
       " 'y_train': 450    0\n",
       " 543    1\n",
       " 157    0\n",
       " 462    0\n",
       " 397    0\n",
       "       ..\n",
       " 820    1\n",
       " 673    1\n",
       " 310    1\n",
       " 72     0\n",
       " 749    0\n",
       " Name: survived, Length: 398, dtype: int64,\n",
       " 'x_validate':      pclass  embark_town_Queenstown  embark_town_Southampton  sex_male\n",
       " 610       3                       0                        1         0\n",
       " 56        2                       0                        1         0\n",
       " 664       3                       0                        1         1\n",
       " 830       3                       0                        0         0\n",
       " 92        1                       0                        1         1\n",
       " ..      ...                     ...                      ...       ...\n",
       " 505       1                       0                        0         1\n",
       " 164       3                       0                        1         1\n",
       " 624       3                       0                        1         1\n",
       " 726       2                       0                        1         0\n",
       " 33        2                       0                        1         1\n",
       " \n",
       " [171 rows x 4 columns],\n",
       " 'y_validate': 610    0\n",
       " 56     1\n",
       " 664    1\n",
       " 830    1\n",
       " 92     0\n",
       "       ..\n",
       " 505    0\n",
       " 164    0\n",
       " 624    0\n",
       " 726    1\n",
       " 33     0\n",
       " Name: survived, Length: 171, dtype: int64,\n",
       " 'x_test':      pclass  embark_town_Queenstown  embark_town_Southampton  sex_male\n",
       " 178       2                       0                        1         1\n",
       " 722       2                       0                        1         1\n",
       " 200       3                       0                        1         1\n",
       " 539       1                       0                        0         0\n",
       " 79        3                       0                        1         0\n",
       " 412       1                       1                        0         0\n",
       " 4         3                       0                        1         1\n",
       " 504       1                       0                        1         0\n",
       " 146       3                       0                        1         1\n",
       " 38        3                       0                        1         0\n",
       " 508       3                       0                        1         1\n",
       " 635       2                       0                        1         0\n",
       " 808       2                       0                        1         1\n",
       " 131       3                       0                        1         1\n",
       " 671       1                       0                        1         1\n",
       " 675       3                       0                        1         1\n",
       " 377       1                       0                        0         1\n",
       " 239       2                       0                        1         1\n",
       " 81        3                       0                        1         1\n",
       " 342       2                       0                        1         1\n",
       " 668       3                       0                        1         1\n",
       " 488       3                       0                        1         1\n",
       " 89        3                       0                        1         1\n",
       " 133       2                       0                        1         0\n",
       " 345       2                       0                        1         0\n",
       " 144       2                       0                        1         1\n",
       " 125       3                       0                        0         1\n",
       " 106       3                       0                        1         0\n",
       " 105       3                       0                        1         1\n",
       " 708       1                       0                        1         0\n",
       " 484       1                       0                        0         1\n",
       " 843       3                       0                        0         1\n",
       " 265       2                       0                        1         1\n",
       " 694       1                       0                        1         1\n",
       " 1         1                       0                        0         0\n",
       " 438       1                       0                        1         1\n",
       " 316       2                       0                        1         0\n",
       " 867       1                       0                        1         1\n",
       " 40        3                       0                        1         0\n",
       " 609       1                       0                        1         0\n",
       " 723       2                       0                        1         1\n",
       " 885       3                       1                        0         0\n",
       " 419       3                       0                        1         0\n",
       " 687       3                       0                        1         1\n",
       " 659       1                       0                        0         1\n",
       " 467       1                       0                        1         1\n",
       " 225       3                       0                        1         1\n",
       " 372       3                       0                        1         1\n",
       " 626       2                       1                        0         1\n",
       " 618       2                       0                        1         0\n",
       " 877       3                       0                        1         1\n",
       " 786       3                       0                        1         0\n",
       " 713       3                       0                        1         1\n",
       " 630       1                       0                        1         1\n",
       " 244       3                       0                        0         1\n",
       " 743       3                       0                        1         1\n",
       " 483       3                       0                        1         0\n",
       " 764       3                       0                        1         1\n",
       " 389       2                       0                        0         0\n",
       " 261       3                       0                        1         1\n",
       " 585       1                       0                        1         0\n",
       " 253       3                       0                        1         1\n",
       " 736       3                       0                        1         0\n",
       " 383       1                       0                        1         0\n",
       " 234       2                       0                        1         1\n",
       " 153       3                       0                        1         1\n",
       " 314       2                       0                        1         1\n",
       " 127       3                       0                        1         1\n",
       " 259       2                       0                        1         0\n",
       " 23        1                       0                        1         1\n",
       " 71        3                       0                        1         0\n",
       " 439       2                       0                        1         1\n",
       " 757       2                       0                        1         1\n",
       " 471       3                       0                        1         1\n",
       " 282       3                       0                        1         1\n",
       " 586       2                       0                        1         1\n",
       " 52        1                       0                        0         0\n",
       " 583       1                       0                        0         1\n",
       " 369       1                       0                        0         0\n",
       " 399       2                       0                        1         0\n",
       " 575       3                       0                        1         1\n",
       " 193       2                       0                        1         1\n",
       " 114       3                       0                        0         0\n",
       " 138       3                       0                        1         1\n",
       " 220       3                       0                        1         1\n",
       " 113       3                       0                        1         0\n",
       " 728       2                       0                        1         1\n",
       " 175       3                       0                        1         1\n",
       " 802       1                       0                        1         1\n",
       " 11        1                       0                        1         0\n",
       " 85        3                       0                        1         0\n",
       " 39        3                       0                        0         0\n",
       " 7         3                       0                        1         1\n",
       " 59        3                       0                        1         1\n",
       " 546       2                       0                        1         0\n",
       " 376       3                       0                        1         0\n",
       " 381       3                       0                        0         0\n",
       " 703       3                       1                        0         1\n",
       " 480       3                       0                        1         1\n",
       " 8         3                       0                        1         0\n",
       " 603       3                       0                        1         1\n",
       " 880       2                       0                        1         0\n",
       " 658       2                       0                        1         1\n",
       " 875       3                       0                        0         0\n",
       " 363       3                       0                        1         1\n",
       " 806       1                       0                        1         1\n",
       " 541       3                       0                        1         0\n",
       " 810       3                       0                        1         1\n",
       " 66        2                       0                        1         0\n",
       " 165       3                       0                        1         1\n",
       " 134       2                       0                        1         1\n",
       " 748       1                       0                        1         1\n",
       " 100       3                       0                        1         0\n",
       " 840       3                       0                        1         1\n",
       " 423       3                       0                        1         0\n",
       " 302       3                       0                        1         1\n",
       " 797       3                       0                        1         0\n",
       " 556       1                       0                        0         0\n",
       " 845       3                       0                        1         1\n",
       " 230       1                       0                        1         0\n",
       " 155       1                       0                        0         1\n",
       " 724       1                       0                        1         1\n",
       " 213       2                       0                        1         1\n",
       " 290       1                       0                        1         0\n",
       " 860       3                       0                        1         1\n",
       " 534       3                       0                        1         0\n",
       " 701       1                       0                        1         1\n",
       " 130       3                       0                        0         1\n",
       " 179       3                       0                        1         1\n",
       " 771       3                       0                        1         1\n",
       " 716       1                       0                        0         0\n",
       " 210       3                       0                        1         1\n",
       " 453       1                       0                        0         1\n",
       " 93        3                       0                        1         1\n",
       " 765       1                       0                        1         0\n",
       " 530       2                       0                        1         0\n",
       " 558       1                       0                        1         0\n",
       " 122       2                       0                        0         1\n",
       " 98        2                       0                        1         0\n",
       " 857       1                       0                        1         1\n",
       " 6         1                       0                        1         1\n",
       " 357       2                       0                        1         0\n",
       " 58        2                       0                        1         0,\n",
       " 'y_test': 178    0\n",
       " 722    0\n",
       " 200    0\n",
       " 539    1\n",
       " 79     1\n",
       " 412    1\n",
       " 4      0\n",
       " 504    1\n",
       " 146    1\n",
       " 38     0\n",
       " 508    0\n",
       " 635    1\n",
       " 808    0\n",
       " 131    0\n",
       " 671    0\n",
       " 675    0\n",
       " 377    0\n",
       " 239    0\n",
       " 81     1\n",
       " 342    0\n",
       " 668    0\n",
       " 488    0\n",
       " 89     0\n",
       " 133    1\n",
       " 345    1\n",
       " 144    0\n",
       " 125    1\n",
       " 106    1\n",
       " 105    0\n",
       " 708    1\n",
       " 484    1\n",
       " 843    0\n",
       " 265    0\n",
       " 694    0\n",
       " 1      1\n",
       " 438    0\n",
       " 316    1\n",
       " 867    0\n",
       " 40     0\n",
       " 609    1\n",
       " 723    0\n",
       " 885    0\n",
       " 419    0\n",
       " 687    0\n",
       " 659    0\n",
       " 467    0\n",
       " 225    0\n",
       " 372    0\n",
       " 626    0\n",
       " 618    1\n",
       " 877    0\n",
       " 786    1\n",
       " 713    0\n",
       " 630    1\n",
       " 244    0\n",
       " 743    0\n",
       " 483    1\n",
       " 764    0\n",
       " 389    1\n",
       " 261    1\n",
       " 585    1\n",
       " 253    0\n",
       " 736    0\n",
       " 383    1\n",
       " 234    0\n",
       " 153    0\n",
       " 314    0\n",
       " 127    1\n",
       " 259    1\n",
       " 23     1\n",
       " 71     0\n",
       " 439    0\n",
       " 757    0\n",
       " 471    0\n",
       " 282    0\n",
       " 586    0\n",
       " 52     1\n",
       " 583    0\n",
       " 369    1\n",
       " 399    1\n",
       " 575    0\n",
       " 193    1\n",
       " 114    0\n",
       " 138    0\n",
       " 220    1\n",
       " 113    0\n",
       " 728    0\n",
       " 175    0\n",
       " 802    1\n",
       " 11     1\n",
       " 85     1\n",
       " 39     1\n",
       " 7      0\n",
       " 59     0\n",
       " 546    1\n",
       " 376    1\n",
       " 381    1\n",
       " 703    0\n",
       " 480    0\n",
       " 8      1\n",
       " 603    0\n",
       " 880    1\n",
       " 658    0\n",
       " 875    1\n",
       " 363    0\n",
       " 806    0\n",
       " 541    0\n",
       " 810    0\n",
       " 66     1\n",
       " 165    1\n",
       " 134    0\n",
       " 748    0\n",
       " 100    0\n",
       " 840    0\n",
       " 423    0\n",
       " 302    0\n",
       " 797    1\n",
       " 556    1\n",
       " 845    0\n",
       " 230    1\n",
       " 155    0\n",
       " 724    1\n",
       " 213    0\n",
       " 290    1\n",
       " 860    0\n",
       " 534    0\n",
       " 701    1\n",
       " 130    0\n",
       " 179    0\n",
       " 771    0\n",
       " 716    1\n",
       " 210    0\n",
       " 453    1\n",
       " 93     0\n",
       " 765    1\n",
       " 530    1\n",
       " 558    1\n",
       " 122    0\n",
       " 98     1\n",
       " 857    1\n",
       " 6      0\n",
       " 357    0\n",
       " 58     1\n",
       " Name: survived, dtype: int64}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_and_y(train,validate,test,features, target = 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d233f748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  embark_town_Queenstown  embark_town_Southampton  sex_male\n",
       "583       1                       0                        0         1\n",
       "165       3                       0                        1         1\n",
       "50        3                       0                        1         1\n",
       "259       2                       0                        1         0\n",
       "306       1                       0                        0         0\n",
       "..      ...                     ...                      ...       ...\n",
       "313       3                       0                        1         1\n",
       "636       3                       0                        1         1\n",
       "222       3                       0                        1         1\n",
       "485       3                       0                        1         0\n",
       "744       3                       0                        1         1\n",
       "\n",
       "[498 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6e7a7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived\n",
       "583         0\n",
       "165         1\n",
       "50          0\n",
       "259         1\n",
       "306         1\n",
       "..        ...\n",
       "313         0\n",
       "636         0\n",
       "222         0\n",
       "485         0\n",
       "744         1\n",
       "\n",
       "[498 rows x 1 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7bb6ce",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a287716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3cd00eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=3, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8a2859a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, random_state=123)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f4348e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2549494  0.02162778 0.03081401 0.69260881]\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a5f71b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(x_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dfd91a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64691191, 0.35308809],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.74993003, 0.25006997],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.08451577, 0.91548423],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.08451577, 0.91548423],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.74993003, 0.25006997],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.74993003, 0.25006997],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.08451577, 0.91548423],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.08451577, 0.91548423],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.74993003, 0.25006997],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.75338375, 0.24661625],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.08451577, 0.91548423],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.08150039, 0.91849961],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.25481767, 0.74518233],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.06618338, 0.93381662],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.65184688, 0.34815312],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87075847, 0.12924153],\n",
       "       [0.84088266, 0.15911734],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.64691191, 0.35308809],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.09916049, 0.90083951],\n",
       "       [0.78508208, 0.21491792],\n",
       "       [0.41786131, 0.58213869],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.87617731, 0.12382269],\n",
       "       [0.5901263 , 0.4098737 ],\n",
       "       [0.87617731, 0.12382269]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = rf.predict_proba(x_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a8211",
   "metadata": {},
   "source": [
    "### Evaluation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c84917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on traing set: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Compute Accuracy\n",
    "print('Accuracy of random forest classifier on traing set: {:.2f}'.format(rf.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bdb6b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294  13]\n",
      " [ 77 114]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "738910ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       307\n",
      "           1       0.90      0.60      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.85      0.78      0.79       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print and clearly label the following: Accuracy, true positive rate, false positive rate,\n",
    "# true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8e30d",
   "metadata": {},
   "source": [
    "### Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ca41690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test test: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on test test: {:.2f}'\n",
    "     .format(rf.score(x_validate,y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb30b5",
   "metadata": {},
   "source": [
    "### Now looking at directions instead of following lesson example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947120b4",
   "metadata": {},
   "source": [
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d8de0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to build a function...\n",
    "def random_forest(train, validate,features , min_samples_leaf, d, print_results = True):\n",
    "    \n",
    "    X_train = train[features]\n",
    "    y_train = train[['survived']]\n",
    "    rf = RandomForestClassifier(max_depth=d, min_samples_leaf=min_samples_leaf, random_state=123)\n",
    "    # Fit\n",
    "    rf = rf.fit(X_train, y_train['survived'])\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = rf.predict(X_train)\n",
    "    \n",
    "    # Results\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
    "    if print_results:\n",
    "        print(\"TRAINING RESULTS\")\n",
    "        print(\"----------------\")\n",
    "        # Feature importance\n",
    "        print(f\"Feature importance:\\n{dict(zip(features,rf.feature_importances_))}\")\n",
    "        print(f\"Accuracy of random forest classifer on training set: {rf.score(X_train, y_train):.2%}\")\n",
    "        print(classification_report(y_train, y_pred))\n",
    "\n",
    "        \n",
    "        print(\"Confusion matrix: rows are truth, columns are pred\")\n",
    "        print(\"\")\n",
    "        print(confusion_matrix(y_train, y_pred))\n",
    "        print(\"\")\n",
    "        print(f\"False positive rate: {fp/(fp+tn):.2%}\")\n",
    "        print(f\"False negative rate: {fn/(fn+tp):.2%}\")\n",
    "        print(f\"True positive rate: {tp/(tp+fn):.2%}\")\n",
    "        print(f\"True negative rate: {tn/(fp+tn):.2%}\")\n",
    "        print(\"----------------\")\n",
    "    train_report = classification_report(y_train, y_pred, output_dict=True)\n",
    "    ### Predict for Validate \n",
    "    y_pred_val = rf.predict(validate[features])\n",
    "    ### Classification report\n",
    "    validate_report = classification_report(validate[['survived']],y_pred_val, output_dict=True)\n",
    "    if print_results:\n",
    "        print(\"VALIDATE RESULTS\")\n",
    "        print(\"----------------\")\n",
    "        print(classification_report(validate[['survived']],y_pred_val))\n",
    "    reports = {'train':train_report,'validate':validate_report}\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d814c583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING RESULTS\n",
      "----------------\n",
      "Feature importance:\n",
      "{'pclass': 0.31157122794183023, 'embark_town_Queenstown': 0.027475321223680762, 'embark_town_Southampton': 0.042824936023002885, 'sex_male': 0.6181285148114861}\n",
      "Accuracy of random forest classifer on training set: 80.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       237\n",
      "           1       0.84      0.64      0.73       161\n",
      "\n",
      "    accuracy                           0.80       398\n",
      "   macro avg       0.81      0.78      0.79       398\n",
      "weighted avg       0.81      0.80      0.80       398\n",
      "\n",
      "Confusion matrix: rows are truth, columns are pred\n",
      "\n",
      "[[217  20]\n",
      " [ 58 103]]\n",
      "\n",
      "False positive rate: 8.44%\n",
      "False negative rate: 36.02%\n",
      "True positive rate: 63.98%\n",
      "True negative rate: 91.56%\n",
      "----------------\n",
      "VALIDATE RESULTS\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82       102\n",
      "           1       0.82      0.52      0.64        69\n",
      "\n",
      "    accuracy                           0.76       171\n",
      "   macro avg       0.78      0.72      0.73       171\n",
      "weighted avg       0.77      0.76      0.75       171\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': {'0': {'precision': 0.7890909090909091,\n",
       "   'recall': 0.9156118143459916,\n",
       "   'f1-score': 0.8476562499999999,\n",
       "   'support': 237},\n",
       "  '1': {'precision': 0.8373983739837398,\n",
       "   'recall': 0.639751552795031,\n",
       "   'f1-score': 0.7253521126760563,\n",
       "   'support': 161},\n",
       "  'accuracy': 0.8040201005025126,\n",
       "  'macro avg': {'precision': 0.8132446415373245,\n",
       "   'recall': 0.7776816835705114,\n",
       "   'f1-score': 0.786504181338028,\n",
       "   'support': 398},\n",
       "  'weighted avg': {'precision': 0.8086323710199185,\n",
       "   'recall': 0.8040201005025126,\n",
       "   'f1-score': 0.7981814607810177,\n",
       "   'support': 398}},\n",
       " 'validate': {'0': {'precision': 0.7401574803149606,\n",
       "   'recall': 0.9215686274509803,\n",
       "   'f1-score': 0.8209606986899565,\n",
       "   'support': 102},\n",
       "  '1': {'precision': 0.8181818181818182,\n",
       "   'recall': 0.5217391304347826,\n",
       "   'f1-score': 0.6371681415929203,\n",
       "   'support': 69},\n",
       "  'accuracy': 0.7602339181286549,\n",
       "  'macro avg': {'precision': 0.7791696492483895,\n",
       "   'recall': 0.7216538789428815,\n",
       "   'f1-score': 0.7290644201414385,\n",
       "   'support': 171},\n",
       "  'weighted avg': {'precision': 0.7716409850682541,\n",
       "   'recall': 0.7602339181286549,\n",
       "   'f1-score': 0.7467987896858892,\n",
       "   'support': 171}}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['pclass','embark_town_Queenstown', 'embark_town_Southampton','sex_male']\n",
    "random_forest(train,validate,features,1,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c2487695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
      "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
      "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
      "support    307.000000  191.000000  0.799197  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
      "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
      "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
      "support    307.000000  191.000000  0.819277  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
      "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
      "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
      "support    307.000000  191.000000  0.819277  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
      "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
      "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
      "support    307.000000  191.000000  0.819277  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
      "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
      "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
      "support    307.000000  191.000000  0.819277  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
      "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
      "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
      "support    307.000000  191.000000  0.819277  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
      "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
      "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
      "support    307.000000  191.000000  0.819277  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
      "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
      "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
      "support    307.000000  191.000000  0.819277  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.792453    0.897638  0.819277    0.845045      0.832795\n",
      "recall       0.957655    0.596859  0.819277    0.777257      0.819277\n",
      "f1-score     0.867257    0.716981  0.819277    0.792119      0.809621\n",
      "support    307.000000  191.000000  0.819277  498.000000    498.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (2,11):\n",
    "    rfc = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "    rfc = rfc.fit(x_train,y_train)\n",
    "    #predictions\n",
    "    y_pred = rfc.predict(x_train)\n",
    "    # Classification loop\n",
    "    report = classification_report(y_train, y_pred, output_dict=True)\n",
    "    print(f'Tree with max depth of {i}')\n",
    "    print(pd.DataFrame(report))\n",
    "    print()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "64bfad5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           1        0.799197           0.761682    0.037515\n",
       "1           2        0.799197           0.761682    0.037515\n",
       "2           3        0.819277           0.794393    0.024885\n",
       "3           4        0.819277           0.794393    0.024885\n",
       "4           5        0.819277           0.794393    0.024885\n",
       "5           6        0.819277           0.794393    0.024885\n",
       "6           7        0.819277           0.794393    0.024885\n",
       "7           8        0.819277           0.794393    0.024885\n",
       "8           9        0.819277           0.794393    0.024885\n",
       "9          10        0.819277           0.794393    0.024885\n",
       "10         11        0.819277           0.794393    0.024885\n",
       "11         12        0.819277           0.794393    0.024885\n",
       "12         13        0.819277           0.794393    0.024885\n",
       "13         14        0.819277           0.794393    0.024885\n",
       "14         15        0.819277           0.794393    0.024885\n",
       "15         16        0.819277           0.794393    0.024885\n",
       "16         17        0.819277           0.794393    0.024885\n",
       "17         18        0.819277           0.794393    0.024885\n",
       "18         19        0.819277           0.794393    0.024885\n",
       "19         20        0.819277           0.794393    0.024885\n",
       "20         21        0.819277           0.794393    0.024885\n",
       "21         22        0.819277           0.794393    0.024885\n",
       "22         23        0.819277           0.794393    0.024885\n",
       "23         24        0.819277           0.794393    0.024885"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copied from decision tree lesson & updted with random forest classifier\n",
    "metrics = []\n",
    "\n",
    "for i in range(1, 25):\n",
    "    # Make the model\n",
    "    rfc = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    rfc = rfc.fit(x_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = rfc.score(x_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = rfc.score(x_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f47cd156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAGqCAYAAADNxBiYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5eklEQVR4nO3de5hVdd3//+dbQOXkAUfRwoLKPGCggmjWraBpYB6TUlPz8FW+Wpra135RdpdW3ql5d5cdNDPz1psisyxNTFNB09SAQk6eSE3xgAgeGAEReP/+mM3cA87ALJm1Z/bwfFzXvthrr7XX6/MZYM9r1qy9V2QmkiRJklpvo/YegCRJklRrLNGSJElSQZZoSZIkqSBLtCRJklSQJVqSJEkqqGt7D6Courq67N+/f+PyG2+8Qc+ePauSXa0s51QbWZ0tp5pZzqk2spxTbWQ5p46fo9o1derUlzNz62ZXZmZN3YYMGZJNTZw4MaulWlnOqTayOltONbOcU21kOafayHJOHT9HtQuYki10Uk/nkCRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKsgSLUmSJBVkiZYkSZIKskRLkiRJBVmiJUmSpIIs0ZIkSVJBlmhJkiSpIEu0JEmSVFDX9h6A2s+ipW+xaFmy8I1l5WdVKaeaWZ0tp5pZzqk2spxTbWQ5p46fo/W3efdudNko2nsYq4nMbO8xFDJ06NCcMmVK4/KkSZMYPnx4VbKrlVVmznOvLuG2GS8wYcYL/P2ZV0vJkCRJakt/Hbs/79qie9VzI2JqZg5tbp1HojcAzy5czJ9mvsitM15g2rOvArDzdpvxhQN2YOHz/2KHHXYofQxPPPFEVXKqmdXZcqqZ5ZxqI8s51UaWc+r4OVp/m3Xv1t5DeBtLdCf17MLFTKgccX547msADHzXZnzp4zsyatdted/WvQCYNOl5hu/Tv/TxTFr2dFVyqpnV2XKqmeWcaiPLOdVGlnPq+DnqnCzRnci/FrzBrTNe4LYZLzLjuYbi/KF3b86XR+7EwR/alvdu1bOdRyhJktQ5WKJr3FMvv8GEGS9w6/QXmP3C6wAM3n4LvjJqJw7+0HZs36dHO49QkiSp87FE16A5L9Vz24wXuHXGCzz64iIAdn/PFnztEzszctdt6belxVmSJKlMpZboiBgJ/ADoAlydmRevsX5z4H+A91TGcllm/qLMMdWqJ+YtYsKMF5kw4wUem9dQnIe8d0v+/ZBdGLXrtu3yjlVJkqQNVWklOiK6AD8GDgTmApMj4ubMnN1ks88DszPz0IjYGngsIsZl5gb/oY2ZyePz6ivnOL/AEy/VEwF7vrcP3zh0F0btuh3bbr5pew9TkiRpg1TmkehhwJzMfBIgIsYDhwNNS3QCvSMigF7AQmB5iWN6R5YsW8Fdj85j9gvLqZ/+fKlZmXDHE8v41tR7+Of8N4iAYf378M3DB/LxgdvSdzOLsyRJUnsr7WIrETEaGJmZp1aWTwD2yswzm2zTG7gZ2AnoDRydmbc2s68xwBiAvn37Dhk/fnzjuvr6enr16lXKHFZZsGQl/++eJaVmNBUkO/Xpwp7bdmWPvl3YYpPyrs5eja9fNXOqmdXZcqqZ5ZxqI8s51UaWc+r4OapdI0aMaJeLrTR3bcY1G/vHgWnA/sD7gT9HxF8y8/XVnpR5FXAVNFyxsOnV/KpxFcG3Vqxk0B5v8LfJkxm2556lZgE8+vAUDj1oRLkhmfDCw/zjb7PYvf9u5WYB/5j2r6rkVDOrs+VUM8s51UaWc6qNLOfU8XPUBt49BLp1rN/Gl1mi5wLbN1nuB6x5LsTJwMXZcDh8TkQ8RcNR6b+VOK7CunXZiB369ua5Xg1/lu25jUu+Nvy/HoA7vwHPPsTu0PBjTMmqlVPNrM6WU80s51QbWc6pNrKcU8fPURs4dxZs3q+9R7GaMkv0ZGCHiBgAPAccA3xmjW2eAQ4A/hIRfYEdgSdLHNOG7aVH4M4L4fHboNe2cPBlTHtuCbsNHlx69LSHH65KTjWzOltONbOcU21kOafayHJOHT9HbaBHXXuP4G1KK9GZuTwizgRup+Ej7q7JzFkRcXpl/ZXAt4BrI2IGDad/fDkzXy5rTBus1+bCxO/Aw7+EjXvDAd+AvU6HjXvw6qRJ8L79Sh/Cq89kVXKqmdXZcqqZ5ZxqI8s51UaWc+r4OeqcSv2c6MycAExY47Erm9x/HjiozDFs0BYvhPu+Bw9dBSTs/Tn4t/8HPfq098gkSZJqmlcs7IyWLYaHroT7vg9vvg67fQaGfwW22H6dT5UkSdK6WaI7kxXLYdo4mPQdWPQCfHAkHPB16DuwvUcmSZLUqViiO4NMePRWuOtCePlx6DcMRl8D792nvUcmSZLUKVmia92//gp//gbM/RvUfRCOHgc7fQKi5I/JkyRJ2oBZomvVvNkNR54f/xP03g4OvRx2Ow66+FcqSZJUNhtXrXn1WZj4H/Dwr2CTzeBjF8Cw/wsb92jvkUmSJG0wLNG1YvFC+Mt/wt9+1rC8z5nw0S/6cXWSJEntwBLd0S1bDA9dAff9AJYtgsGfgeFj/bg6SZKkdmSJ7qhWLIdp/wOTLq58XN2oysfV7dLeI5MkSdrgWaI7mkzq5j8APzkPFjwB2+8Fo38B7/1we49MkiRJFZbo1nhtLvzXQIYDTCo/bleAuh3hmF/Cjgf7cXWSJEkdjCW6NTbpDfuN5emnn6Z///6lxz0y7012/tTX/Lg6SZKkDsqW1hqbbg4jvsLTkybRf/jw0uPmTZrEzhZoSZKkDmuj9h6AJEmSVGss0ZIkSVJBlmhJkiSpIEu0JEmSVJAlWpIkSSrIEi1JkiQVZImWJEmSCrJES5IkSQVZoiVJkqSCLNGSJElSQZZoSZIkqSBLtCRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKqjUEh0RIyPisYiYExFjm1n/pYiYVrnNjIgVEdGnzDFJkiRJ66u0Eh0RXYAfA6OAXYBjI2KXpttk5nczc7fM3A34CnBPZi4sa0ySJElSWyjzSPQwYE5mPpmZy4DxwOFr2f5Y4FcljkeSJElqE2WW6HcDzzZZnlt57G0iogcwEvhtieORJEmS2kRkZjk7jvgU8PHMPLWyfAIwLDPPambbo4HjM/PQFvY1BhgD0Ldv3yHjx49vXFdfX0+vXr1KmMHbVSvLOdVGVmfLqWaWc6qNLOdUG1nOqePnqHaNGDFiamYObXZlZpZyAz4M3N5k+SvAV1rY9ibgM63Z75AhQ7KpiRMnZrVUK8s51UZWZ8upZpZzqo0s51QbWc6p4+eodgFTsoVOWubpHJOBHSJiQERsDBwD3LzmRhGxObAf8IcSxyJJkiS1ma5l7Tgzl0fEmcDtQBfgmsycFRGnV9ZfWdn0SOCOzHyjrLFIkiRJbam0Eg2QmROACWs8duUay9cC15Y5DkmSJKktecVCSZIkqSBLtCRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKsgSLUmSJBVkiZYkSZIKskRLkiRJBVmiJUmSpIIs0ZIkSVJBlmhJkiSpIEu0JEmSVJAlWpIkSSrIEi1JkiQVZImWJEmSCrJES5IkSQVZoiVJkqSCLNGSJElSQZZoSZIkqSBLtCRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKqjUEh0RIyPisYiYExFjW9hmeERMi4hZEXFPmeORJEmS2kLXsnYcEV2AHwMHAnOByRFxc2bObrLNFsBPgJGZ+UxEbFPWeCRJkqS2UuaR6GHAnMx8MjOXAeOBw9fY5jPA7zLzGYDMfKnE8UiSJEltIjKznB1HjKbhCPOpleUTgL0y88wm23wf6AYMBHoDP8jM65rZ1xhgDEDfvn2HjB8/vnFdfX09vXr1KmUOa6pWlnOqjazOllPNLOdUG1nOqTaynFPHz1HtGjFixNTMHNrsysws5QZ8Cri6yfIJwA/X2OZHwINAT6AOeAL44Nr2O2TIkGxq4sSJWS3VynJOtZHV2XKqmeWcaiPLOdVGlnPq+DmqXcCUbKGTlnZONA3nQW/fZLkf8Hwz27ycmW8Ab0TEvcBg4PESxyVJkiStlzLPiZ4M7BARAyJiY+AY4OY1tvkD8G8R0TUiegB7AY+UOCZJkiRpvZV2JDozl0fEmcDtQBfgmsycFRGnV9ZfmZmPRMSfgOnAShpO/5hZ1pgkSZKktlDm6Rxk5gRgwhqPXbnG8neB75Y5DkmSJKktecVCSZIkqSBLtCRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKsgSLUmSJBVkiZYkSZIKskRLkiRJBVmiJUmSpIIs0ZIkSVJBlmhJkiSpIEu0JEmSVJAlWpIkSSrIEi1JkiQVZImWJEmSCrJES5IkSQVZoiVJkqSCLNGSJElSQZZoSZIkqSBLtCRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKqjUEh0RIyPisYiYExFjm1k/PCJei4hpldvXyxyPJEmS1Ba6lrXjiOgC/Bg4EJgLTI6ImzNz9hqb/iUzDylrHJIkSVJbK/NI9DBgTmY+mZnLgPHA4SXmSZIkSVURmVnOjiNGAyMz89TK8gnAXpl5ZpNthgO/peFI9fPAeZk5q5l9jQHGAPTt23fI+PHjG9fV19fTq1evUuawpmplOafayOpsOdXMck61keWcaiPLOXX8HNWuESNGTM3Moc2uzMxSbsCngKubLJ8A/HCNbTYDelXuHww8sa79DhkyJJuaOHFiVku1spxTbWR1tpxqZjmn2shyTrWR5Zw6fo5qFzAlW+ikZZ7OMRfYvslyPxqONjct8K9nZn3l/gSgW0TUlTgmSZIkab2VWaInAztExICI2Bg4Bri56QYRsW1EROX+sMp4FpQ4JkmSJGm9lfbpHJm5PCLOBG4HugDXZOasiDi9sv5KYDRwRkQsB5YAx1QOnUuSJEkdVmklGhpP0ZiwxmNXNrn/I+BHZY5BkiRJamtesVCSJEkqyBItSZIkFWSJliRJkgoq9ZxoSZKkWvLWW28xd+5cli5d2t5DURVtuumm9OvXj27durX6OZZoSZKkirlz59K7d2/69+9P5VN41cllJgsWLGDu3LkMGDCg1c/zdA5JkqSKpUuXstVWW1mgNyARwVZbbVX4tw+WaEmSpCYs0Bued/J3vs4SHRGHRIRlW5IkSapoTTk+BngiIi6NiJ3LHpAkSdKG7NVXX+UnP/lJ4ecdfPDBvPrqq20/IDVrnSU6M48Hdgf+CfwiIh6IiDER0bv00UmSJG1gWirRK1asWOvzJkyYwBZbbFHSqNbfusZfa1r16RyZ+XpE/BboDpwDHAl8KSIuz8wfljg+SZKkdnHhLbOY/fzrbbrPXd61Gd84dOBatxk7diz//Oc/2W233ejWrRu9evViu+22Y9q0acyePZsjjjiCZ599lqVLl3L22WczZswYAPr378+UKVOor69n1KhRfPSjH+Wvf/0r7373u/nDH/5A9+7dm8372c9+xlVXXcWyZcv4wAc+wPXXX0+PHj2YN28ep59+Ok8++SQAV1xxBfvssw/XXXcdl112GRHBoEGDuP766znppJM45JBDGD16NAC9evWivr6eSZMmceGFF7Zq/H/605/46le/yooVK6irq+PPf/4zO+64I3/961/ZeuutWblyJR/84Ad58MEHqaura6u/kndsnSU6Ig4FTgHeD1wPDMvMlyKiB/AIYImWJElqIxdffDEzZ85k2rRpTJo0iU984hPMnDmz8ePXrrnmGvr06cOSJUvYc889Oeqoo9hqq61W28cTTzzBr371K372s5/x6U9/mt/+9rccf/zxzeZ98pOf5LTTTgPga1/7Gj//+c8566yz+MIXvsB+++3HTTfdxIoVK6ivr2fWrFlcdNFF3H///dTV1bFw4cJ1zudvf/vbOse/cuVKTjvtNO69914GDBjAwoUL2WijjTj++OMZN24c55xzDnfeeSeDBw/uEAUaWnck+lPAf2XmvU0fzMzFEXFKOcOSJElqX+s6Ylwtw4YNW+3ziy+//HJuuukmAJ599lmeeOKJt5XoAQMGsNtuuwEwZMgQnn766Rb3P3PmTL72ta/x6quvUl9fz8c//nEA7r77bq677joAunTpwuabb851113H6NGjG4tsnz592mT88+fPZ999923cbtV+TznlFA4//HDOOeccrrnmGk4++eR15lVLa0r0N4AXVi1ERHegb2Y+nZl3lTYySZIk0bNnz8b7kyZN4s477+SBBx6gR48eDB8+vNnPN95kk00a73fp0oUlS5a0uP+TTjqJ3//+9wwePJhrr72WSZMmtbhtZjb7cXBdu3Zl5cqVjdssW7as0Phb2u/2229P3759ufvuu3nooYcYN25ci2OrttZ8OsdvgJVNlldUHpMkSVIb6927N4sWLWp23WuvvcaWW25Jjx49ePTRR3nwwQfXO2/RokVst912vPXWW6uV1AMOOIArrrgCaHhT4Ouvv84BBxzADTfcwIIFCwAaT+fo378/U6dOBeAPf/gDb731VqHxf/jDH+aee+7hqaeeWm2/AKeeeirHH388n/70p+nSpct6z7ettKZEd83Mxh8nKvc3Lm9IkiRJG66tttqKj3zkI+y666586UtfWm3dyJEjWb58OYMGDeLf//3f2Xvvvdc771vf+hZ77bUXBx54IDvttFPj4z/4wQ+YOHEiH/rQhxgyZAizZs1i4MCBnH/++ey3334MHjyYL37xiwCcdtpp3HPPPQwbNoyHHnpotaPPrRn/1ltvzVVXXcUnP/lJBg8ezNFHH934nMMOO4z6+voOdSoHtO50jvkRcVhm3gwQEYcDL5c7LEmSpA3XL3/5y2Yf32STTbjtttuaXbfqvOe6ujpmzpzZ+Ph555231qwzzjiDM844422P9+3blz/84Q9ve/zEE0/kxBNPfNu2TY+Kf+c73wFg+PDhDB8+vFXjHzVqFKNGjXrb4w8//DCDBw9ereB3BK0p0acD4yLiR0AAzwKfLXVUkiRJ2uBdfPHFXHHFFR3qXOhV1lmiM/OfwN4R0QuIzGz+JB1JkiR1WJ///Oe5//77V3vs7LPP7nCnSTQ1duxYxo4d297DaFarLrYSEZ8ABgKbrnrnZGZ+s8RxSZIkqQ39+Mc/bu8hdCrrfGNhRFwJHA2cRcPpHJ8C3lvyuCRJkqQOqzWfzrFPZn4WeCUzLwQ+DGxf7rAkSZKkjqs1JXrVJ3gvjoh3AW8BA9ayvSRJktSpteac6FsiYgvgu8DfgQR+VuagJEmSpI5srUeiI2Ij4K7MfDUzf0vDudA7ZebXqzI6SZIkrVWvXr0AeP755xk9enSz2wwfPpwpU6asdT/f//73Wbx4cZuPr7Naa4nOzJXAfzZZfjMzXyt9VJIkSSrkXe96FzfeeOM7fn4tlOjly5e39xAateZ0jjsi4ijgd5mZZQ9IkiSpQ7htLLw4o233ue2HYNTFa93ky1/+Mu9973v53Oc+B8AFF1xARHDvvffyyiuv8NZbb/Htb3+bww8/fLXnPf300xxyyCHMnDmTJUuWcPLJJzN79mx23nlnlixZ0rjdGWecweTJk1myZAmjR4/mwgsv5PLLL+f5559nxIgR1NXVMXHiRO644w6+8Y1v8Oabb/L+97+fX/ziF41Hvdf0zW9+k1tuuYUlS5awzz778NOf/pSIYM6cOZx++unMnz+fLl268Jvf/Ib3v//9XHrppVx//fVstNFGjBo1iosvvpjhw4dz2WWXMXToUF5++WWGDh3K008/zbXXXsutt97K0qVLeeONN7j55ps5/PDDm/1aXHfddVx22WVEBIMGDeInP/kJgwYN4vHHH6dbt268/vrrDBo0iCeeeIJu3bqtz99kq0r0F4GewPKIWErDx9xlZm62XsmSJEl6m2OOOYZzzjmnsUTfcMMN/OlPf+Lcc89ls8024+WXX2bvvffmsMMOY9X1O9Z0xRVX0KNHD6ZPn8706dPZY489GtdddNFF9OnThxUrVnDAAQcwffp0vvCFL/C9732PiRMnUldXx8svv8y3v/1t7rzzTnr27Mkll1zC9773Pb7+9ebP6D3zzDMb151wwgn88Y9/5NBDD+W4445j7NixHHnkkSxdupSVK1dy22238fvf/56HHnqIHj16sHDhwnV+TR544AGmT59Onz59WL58OTfddNPbvhazZ8/moosu4v7776euro6FCxfSu3dvhg8fzq233soRRxzB+PHjOeqoo9a7QEPrrljYe71TJEmSas06jhiXZffdd+ell17i+eefZ/78+Wy55ZZst912nHvuudx7771stNFGPPfcc8ybN49tt9222X3ce++9fOELXwBg0KBBDBo0qHHdDTfcwFVXXcXy5ct54YUXmD179mrrAR588EFmz57NRz7yEQCWLVvGhz/84RbHPHHiRC699FIWL17MwoULGThwIMOHD+e5557jyCOPBGDTTTcF4M477+Tkk0+mR48eAPTp02edX5MDDzywcbvM5Ktf/erbvhZ33303o0ePpq6ubrX9nnrqqVx66aUcccQR/OIXv+BnP2ubz8dYZ4mOiH2bezwz722TEUiSJGk1o0eP5sYbb+TFF1/kmGOOYdy4ccyfP5+pU6fSrVs3+vfvz9KlS9e6j+aOUj/11FNcdtllTJ48mS233JKTTjqp2f1kJgceeCC/+tWv1jnWpUuX8rnPfY4pU6aw/fbbc8EFF7B06VJaOgs4M5sdW9euXVm5cmXjPpvq2bNn4/2WvhYt7fcjH/kITz/9NPfccw8rVqxg1113XeecWqM1nxP9pSa3fwduAS5ok3RJkiS9zTHHHMP48eO58cYbGT16NK+99hrbbLMN3bp1Y+LEifzrX/9a6/P33Xdfxo0bB8DMmTOZPn06AK+//jo9e/Zk8803Z968edx2222Nz+nduzeLFi0CYO+99+b+++9nzpw5ACxevJjHH3+82axVhbeuro76+vrGNzduttlm9OvXj9///vcAvPnmmyxevJiDDjqIa665pvFNjKtO5+jfvz9Tp04FWOsbJFv6WhxwwAHccMMNLFiwYLX9Anz2s5/l2GOP5eSTT17r162IdZbozDy0ye1AYFdgXpuNQJIkSasZOHAgixYt4t3vfjfbbbcdxx13HFOmTGHo0KGMGzeOnXbaaa3PP+OMM6ivr2fQoEFceumlDBs2DIDBgwez++67M3DgQE455ZTG0zUAxowZw6hRoxgxYgRbb7011157LcceeyyDBg1i77335tFHH202a4sttuC0007jQx/6EEcccQR77rln47rrr7+eyy+/nEGDBrHPPvvw4osvMnLkSA477DCGDh3KbrvtxmWXXQbAeeedxxVXXME+++zDyy+/3OLcWvpaDBw4kPPPP5/99tuPwYMH88UvfnG157zyyisce+yx6/jKt15r3li4prk0FGlJkiSVZMaM//1kkLq6Oh544IFmt6uvrwcajuTOnDkTgO7duzN+/Phmt7/22mubffyss87irLPOalzef//9mTx5cqvG+u1vf5tvf/vbb3t8hx124O67737b42PHjmXs2LGrPbbTTjs1HjFftU+Ak046iZNOOqnx8bV9LU488UROPPHEtz1+3333MXr0aLbYYovWTKdVWnNO9A9puEohNBy53g14uM1GIEmSJJXkrLPO4rbbbmPChAltut/WHIluenmb5cCvMvP+1uw8IkYCPwC6AFdnZrNvc42IPYEHgaMz851/SrgkSZJKc+SRR/LUU0+t9tgll1zCxz/+8XYa0br98Ic/LGW/rSnRNwJLM3MFQER0iYgembnWS9pERBfgx8CBNJwCMjkibs7M2c1sdwlw+zuZgCRJkqrjpptuau8hdBit+XSOu4DuTZa7A3e24nnDgDmZ+WRmLgPGA4c3s91ZwG+Bl1qxT0mSJKndxbqu5B0R0zJzt3U91szzRgMjM/PUyvIJwF6ZeWaTbd4N/BLYH/g58MfmTueIiDHAGIC+ffsOaXqifH19fYuXoGxr1cpyTrWR1dlyqpnlnGojyznVRpZzatuczTffnA984AOlZ6vjmTNnDq+99tpqj40YMWJqZg5t9gmZudYbcD+wR5PlIcADrXjep2g4D3rV8gnAD9fY5jfA3pX71wKj17XfIUOGZFMTJ07MaqlWlnOqjazOllPNLOdUG1nOqTaynFPb5syePbsq2ep4mvu7B6ZkC520NedEnwP8JiKeryxvBxzdiufNBbZvstwPeH6NbYYC4ytXl6kDDo6I5Zn5+1bsX5IkqdO74IIL6NWrF6+//jr77rsvH/vYx/jLX/7C6aefTrdu3XjggQf4+te/zoQJEzj44IP57ne/295D3iCss0Rn5uSI2AnYEQjg0cx8qxX7ngzsEBEDgOeAY4DPrLHvAavuR8S1NJzO8ftWj16SJGkD8c1vfrPx/rhx4zjvvPMar8D305/+lPnz57PJJpu0al/Lly+na9d3crkQrbLONxZGxOeBnpk5MzNnAL0i4nPrel5mLgfOpOFTNx4BbsjMWRFxekScvr4DlyRJ6qwuuugidtxxRz72sY/x2GOPAQ0XHbnxxhu5+uqrueGGG/jmN7/Jcccdx2GHHcYbb7zBXnvtxa9//Wvmz5/PUUcdxZ577smee+7J/fc3fDLxBRdcwJgxYzjooIP47Gc/u9btTjnlFIYPH8773vc+Lr/88sZxXXfddQwaNIjBgwdzwgknALS4n86uNT+CnJaZP161kJmvRMRpwE/W9cTMnABMWOOxK1vY9qRWjEWSJKkqLvnbJTy6sPlLXb9TO/XZiS8P+/Jat5k6dSrjx4/nH//4B8uXL2ePPfZgyJAhjetPPfVU7rvvPg455BBGjx4NQK9evZg2bRoAn/nMZzj33HP56Ec/yjPPPMPHP/5xHnnkkcZ933fffXTv3n2t2z366KNMnDiRRYsWseOOO3LGGWfw+OOPc9FFF3H//fdTV1fHwoULATj77LNb3E9n1poSvVFEROXk6lWf67xxucOSJEnaMP3lL3/hyCOPpEePHgAcdthhhZ5/5513Mnv2/16W4/XXX2fRokWN++revfs6t/vEJz7BJptswiabbMI222zDvHnzuPvuuxk9ejR1dXUA9OnTZ6376d27d9Gp15TWlOjbgRsi4koaLv99OnBbqaOSJElqZ+s6YlymyocuvCMrV67kgQceaCzLTfXs2bNV2zU9t7pLly4sX76czGx2XGvbT2fWmoutfJmGC66cAXwemM7qF1+RJElSG9l333256aabWLJkCYsWLeKWW24p9PyDDjqIH/3oR43Lq07zeKfbrXLAAQdwww03sGDBAoDG0zmK7qezWGeJzsyVwIPAkzR8JN0BNLxRUJIkSW1sjz324Oijj2a33XbjqKOO4t/+7d8KPf/yyy9nypQpDBo0iF122YUrr2z27Wit3m6VgQMHcv7557PffvsxePBgvvjFL76j/XQWLZ7OEREfpOFj6Y4FFgC/BsjMEdUZmiRJ0obp/PPP5/zzz29x/bXXXrvacn19feP9uro6fv3rX7/tORdccMFqy63dbubMmY33TzzxRE488cRW7aezW9s50Y8CfwEOzcw5ABFxblVGJUmSJHVgazud4yjgRWBiRPwsIg6g4WIrkiRJ0gatxRKdmTdl5tHATsAk4Fygb0RcEREHVWl8kiRJUofTmjcWvpGZ4zLzEKAfMA0YW/bAJEmS2kPl0hjagLyTv/PWfMRd04CFmfnTzNy/cJIkSVIHt+mmm7JgwQKL9AYkM1mwYAGbbrppoee15mIrkiRJG4R+/foxd+5c5s+f395DURVtuumm9OvXr9BzLNGSJEkV3bp1Y8CAAe09DNWAQqdzSJIkSbJES5IkSYVZoiVJkqSCLNGSJElSQZZoSZIkqSBLtCRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKsgSLUmSJBVkiZYkSZIKskRLkiRJBVmiJUmSpIIs0ZIkSVJBlmhJkiSpIEu0JEmSVJAlWpIkSSqo1BIdESMj4rGImBMRY5tZf3hETI+IaRExJSI+WuZ4JEmSpLbQtawdR0QX4MfAgcBcYHJE3JyZs5tsdhdwc2ZmRAwCbgB2KmtMkiRJUlso80j0MGBOZj6ZmcuA8cDhTTfIzPrMzMpiTyCRJEmSOrj43w7bxjuOGA2MzMxTK8snAHtl5plrbHck8B1gG+ATmflAM/saA4wB6Nu375Dx48c3rquvr6dXr16lzGFN1cpyTrWR1dlyqpnlnGojyznVRpZz6vg5ql0jRoyYmplDm12ZmaXcgE8BVzdZPgH44Vq23xe4c137HTJkSDY1ceLErJZqZTmn2sjqbDnVzHJOtZHlnGojyzl1/BzVLmBKttBJyzydYy6wfZPlfsDzLW2cmfcC74+IuhLHJEmSJK23Mkv0ZGCHiBgQERsDxwA3N90gIj4QEVG5vwewMbCgxDFJkiRJ6620T+fIzOURcSZwO9AFuCYzZ0XE6ZX1VwJHAZ+NiLeAJcDRlUPnkiRJUodVWokGyMwJwIQ1Hruyyf1LgEvKHIMkSZLU1rxioSRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKsgSLUmSJBVkiZYkSZIKskRLkiRJBVmiJUmSpIIs0ZIkSVJBlmhJkiSpIEu0JEmSVJAlWpIkSSrIEi1JkiQVZImWJEmSCrJES5IkSQVZoiVJkqSCLNGSJElSQZZoSZIkqSBLtCRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKqjUEh0RIyPisYiYExFjm1l/XERMr9z+GhGDyxyPJEmS1BZKK9ER0QX4MTAK2AU4NiJ2WWOzp4D9MnMQ8C3gqrLGI0mSJLWVMo9EDwPmZOaTmbkMGA8c3nSDzPxrZr5SWXwQ6FfieCRJkqQ2EZlZzo4jRgMjM/PUyvIJwF6ZeWYL258H7LRq+zXWjQHGAPTt23fI+PHjG9fV19fTq1evEmbwdtXKck61kdXZcqqZ5ZxqI8s51UaWc+r4OapdI0aMmJqZQ5tdmZml3IBPAVc3WT4B+GEL244AHgG2Wtd+hwwZkk1NnDgxq6VaWc6pNrI6W041s5xTbWQ5p9rIck4dP0e1C5iSLXTSriWW97nA9k2W+wHPr7lRRAwCrgZGZeaCEscjSZIktYkyz4meDOwQEQMiYmPgGODmphtExHuA3wEnZObjJY5FkiRJajOlHYnOzOURcSZwO9AFuCYzZ0XE6ZX1VwJfB7YCfhIRAMuzpfNOJEmSpA6izNM5yMwJwIQ1Hruyyf1Tgbe9kVCSJEnqyLxioSRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKsgSLUmSJBVkiZYkSZIKskRLkiRJBVmiJUmSpIIs0ZIkSVJBlmhJkiSpIEu0JEmSVJAlWpIkSSrIEi1JkiQVZImWJEmSCrJES5IkSQVZoiVJkqSCLNGSJElSQZZoSZIkqSBLtCRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJUkCVakiRJKsgSLUmSJBVUaomOiJER8VhEzImIsc2s3ykiHoiINyPivDLHIkmSJLWVrmXtOCK6AD8GDgTmApMj4ubMnN1ks4XAF4AjyhqHJEmS1NbKPBI9DJiTmU9m5jJgPHB40w0y86XMnAy8VeI4JEmSpDYVmVnOjiNGAyMz89TK8gnAXpl5ZjPbXgDUZ+ZlLexrDDAGoG/fvkPGjx/fuK6+vp5evXq1/QSaUa0s51QbWZ0tp5pZzqk2spxTbWQ5p46fo9o1YsSIqZk5tNmVmVnKDfgUcHWT5ROAH7aw7QXAea3Z75AhQ7KpiRMnZrVUK8s51UZWZ8upZpZzqo0s51QbWc6p4+eodgFTsoVOWubpHHOB7Zss9wOeLzFPkiRJqooyS/RkYIeIGBARGwPHADeXmCdJkiRVRWmfzpGZyyPiTOB2oAtwTWbOiojTK+uvjIhtgSnAZsDKiDgH2CUzXy9rXJIkSdL6Kq1EA2TmBGDCGo9d2eT+izSc5iFJkiTVDK9YKEmSJBVkiZYkSZIKskRLkiRJBVmiJUmSpIIs0ZIkSVJBlmhJkiSpIEu0JEmSVJAlWpIkSSrIEi1JkiQVZImWJEmSCrJES5IkSQVZoiVJkqSCLNGSJElSQZZoSZIkqSBLtCRJklSQJVqSJEkqyBItSZIkFWSJliRJkgqyREuSJEkFWaIlSZKkgrq29wBqwatLX+U/HvoP5s2fx4R7JpSet2jBIl554hV2rduV923+Prps1KX0TEmSJLWeJboV3lr5Fo8sfITFyxazcOHC0vNefONF7vvrfQB079qdnfvszK51uzbe+vXqR0SUPg5JkiQ1zxLdClv32JpbjryFSZMmMXz48NLz7p54NwP2GMDMl2c23BbMZPyj41m2chkAW2yyBQO3GsjAuoHsulVDsd66x9alj0uSJEkNLNEd0EaxEQM2H8CAzQdw6PsPBRqOhs95ZQ4zXp7BrAWzmPnyTH4+4+esyBUA9O3Rd7Wj1QO3GkjvjXu35zQkSZI6LUt0jei2UTd23mpndt5q58bHlixfwqMLH2XG/BnMXDCTWS/P4q5n7mpc33+z/qsdrd6pz05s2nXT9hi+JElSp2KJrmHdu3Zn9212Z/dtdm987LU3X2s8Uj3z5ZlMfmEytz55KwBdoysf2PIDDNxqILvW7crOW+3MvLfm8dRrT5U+1mrlVDOrs+VUM8s51UaWc6qNLOfU8XO0/vr17ke3jbq19zBWE5nZ3mMoZOjQoTllypTG5Wqdp1zNrLbOeWnxS/97fnXlHOtFyxa12f4lSZLK9OfRf2bbnttWPTcipmbm0ObWeSR6A7BNj23Y/z37s/979gcgM3l20bM89spjPDzzYXbZeZfSxzD7kdlVyalmVmfLqWaWc6qNLOdUG1nOqePnaP1ttvFm7T2Et7FEb4Aigvds9h7es9l76PZUN4a/b3jpmT2e6VGVnGpmdbacamY5p9rIck61keWcOn6OOievWChJkiQVZImWJEmSCrJES5IkSQVZoiVJkqSCLNGSJElSQaWW6IgYGRGPRcSciBjbzPqIiMsr66dHxB5ljkeSJElqC6WV6IjoAvwYGAXsAhwbEWt+GOMoYIfKbQxwRVnjkSRJktpKmUeihwFzMvPJzFwGjAcOX2Obw4HrssGDwBYRsV2JY5IkSZLWW2mX/Y6I0cDIzDy1snwCsFdmntlkmz8CF2fmfZXlu4AvZ+aUNfY1hoYj1fTt23fI+PHjG9fV19fTq1evUuawpmplOafayOpsOdXMck61keWcaiPLOXX8HNWuESNGtHjZbzKzlBvwKeDqJssnAD9cY5tbgY82Wb4LGLK2/Q4ZMiSbmjhxYlZLtbKcU21kdbacamY5p9rIck61keWcOn6OahcwJVvopGWezjEX2L7Jcj/g+XewjSRJktShlFmiJwM7RMSAiNgYOAa4eY1tbgY+W/mUjr2B1zLzhRLHJEmSJK23rmXtODOXR8SZwO1AF+CazJwVEadX1l8JTAAOBuYAi4GTyxqPJEmS1FZKK9EAmTmBhqLc9LErm9xP4PNljkGSJElqa16xUJIkSSqotI+4K0tEzAf+1eShOuDlKsVXK8s51UZWZ8upZpZzqo0s51QbWc6p4+eodr03M7dubkXNleg1RcSUbOnz+2o0yznVRlZny6lmlnOqjSznVBtZzqnj56hz8nQOSZIkqSBLtCRJklRQZyjRV3XCLOdUG1mdLaeaWc6pNrKcU21kOaeOn6NOqObPiZYkSZKqrTMciZYkSZKqyhItSZIkFVTTJToiRkbEYxExJyLGlphzTUS8FBEzy8qo5GwfERMj4pGImBURZ5eUs2lE/C0iHq7kXFhGTpO8LhHxj4j4Y8k5T0fEjIiYFhFTSs7aIiJujIhHK39fHy4hY8fKXFbdXo+Ic9o6p5J1buXfwsyI+FVEbFpGTiXr7ErOrLaeT3P/VyOiT0T8OSKeqPy5ZUk5n6rMaWVEtNlHZrWQ9d3Kv73pEXFTRGxRUs63KhnTIuKOiHhXGTlN1p0XERkRdeub01JWRFwQEc81+X91cBk5lcfPqnyPmhURl65vTktZEfHrJvN5OiKmlZSzW0Q8uOo1NiKGrW/OWrIGR8QDldf0WyJiszbIafZ7bBmvEdpAZGZN3oAuwD+B9wEbAw8Du5SUtS+wBzCz5DltB+xRud8beLyMOQEB9Krc7wY8BOxd4ry+CPwS+GPJX7+ngboyM5pk/TdwauX+xsAWJed1AV6k4UPf23rf7waeArpXlm8ATippHrsCM4EeQFfgTmCHNtz/2/6vApcCYyv3xwKXlJSzM7AjMAkYWvKcDgK6Vu5fUuKcNmty/wvAlWXkVB7fHridhotptcn/4xbmdAFwXlv9/awlZ0Tl3/cmleVtyspaY/1/Al8vaU53AKMq9w8GJpX49ZsM7Fe5fwrwrTbIafZ7bBmvEd42jFstH4keBszJzCczcxkwHji8jKDMvBdYWMa+18h5ITP/Xrm/CHiEhoLT1jmZmfWVxW6VWynvMI2IfsAngKvL2H97qBwR2Rf4OUBmLsvMV0uOPQD4Z2b+a51bvjNdge4R0ZWGgvt8STk7Aw9m5uLMXA7cAxzZVjtv4f/q4TT80EPlzyPKyMnMRzLzsfXddyuz7qh8/QAeBPqVlPN6k8WetMHrxFpeT/8L+P/aIqMVWW2qhZwzgIsz883KNi+VmAVARATwaeBXJeUksOqI8Oa00etEC1k7AvdW7v8ZOKoNclr6HtvmrxHaMNRyiX438GyT5bmUUDjbS0T0B3an4ShxGfvvUvmV30vAnzOzlBzg+zR8Y1xZ0v6bSuCOiJgaEWNKzHkfMB/4ReU0lasjomeJeQDH0AbfGJuTmc8BlwHPAC8Ar2XmHWVk0XAUet+I2CoietBwNGv7krJW6ZuZL0DDN1Fgm5Lzqu0U4Laydh4RF0XEs8BxwNdLyjgMeC4zHy5j/804s3KayjUl/ur+g8C/RcRDEXFPROxZUk5T/wbMy8wnStr/OcB3K/8eLgO+UlIONLxWHFa5/yna+HVije+xnf01QiWp5RIdzTzWKT6vLyJ6Ab8FzlnjSFCbycwVmbkbDUewhkXErm2dERGHAC9l5tS23ncLPpKZewCjgM9HxL4l5XSl4VePV2Tm7sAbNPwKsBQRsTEN30x+U9L+t6ThSMwA4F1Az4g4voyszHyEhtMP/gz8iYbTsJav9UlqUUScT8PXb1xZGZl5fmZuX8k4s633X/lh6nxKKujNuAJ4P7AbDT80/mdJOV2BLYG9gS8BN1SOFJfpWEr6YbviDODcyr+Hc6n8Nq4kp9DwOj6VhlMvlrXVjqvxPVYbhlou0XNZ/SfTfpT3K+iqiYhuNPznHpeZvys7r3IawiRgZAm7/whwWEQ8TcPpNvtHxP+UkANAZj5f+fMl4CYaTvkpw1xgbpOj9zfSUKrLMgr4e2bOK2n/HwOeysz5mfkW8Dtgn5KyyMyfZ+YembkvDb/CLeuo2SrzImI7gMqfbfJr9fYWEScChwDHZWY1DiD8kjb4lXoz3k/DD3APV14r+gF/j4htS8giM+dVDiKsBH5Gua8Tv6ucPvc3Gn4b1yZvmGxO5VSsTwK/LisDOJGG1wdo+KG+rK8dmfloZh6UmUNo+MHgn22x3xa+x3bK1wiVr5ZL9GRgh4gYUDlSdwxwczuPab1UjlL8HHgkM79XYs7Wq97NHxHdaShRj7Z1TmZ+JTP7ZWZ/Gv5+7s7MUo5wRkTPiOi96j4Nb7wq5dNUMvNF4NmI2LHy0AHA7DKyKso+uvQMsHdE9Kj8GzyAhnMFSxER21T+fA8N3/TLnBs0vC6cWLl/IvCHkvNKFxEjgS8Dh2Xm4hJzdmiyeBjlvE7MyMxtMrN/5bViLg1v/nqxrbOgsSStciQlvU4Avwf2r2R+kIY3IL9cUhZUXsczc26JGc8D+1Xu70+JPwA3eZ3YCPgacGUb7LOl77Gd7jVCVdLe72xcnxsN51M+TsNPqOeXmPMrGn7t9xYNL/D/p6Scj9JwSsp0YFrldnAJOYOAf1RyZtIG7+RuReZwSvx0DhrOU364cptV5r+HSt5uwJTK1/D3wJYl5fQAFgCblzyfC2koSDOB66l8okBJWX+h4YeOh4ED2njfb/u/CmwF3EXDN/y7gD4l5RxZuf8mMA+4vcQ5zaHhPSGrXifa4lMzmsv5beXfxHTgFuDdZeSssf5p2u7TOZqb0/XAjMqcbga2KylnY+B/Kl+/vwP7lzWnyuPXAqe3RcZa5vRRYGrl/+5DwJASs86m4fv748DFVK6wvJ45zX6PLeM1wtuGcfOy35IkSVJBtXw6hyRJktQuLNGSJElSQZZoSZIkqSBLtCRJklSQJVqSJEkqyBItSZIkFWSJlqQNTEQ8HRHv6Op5EXFSRLyrLfYlSbXMEi1JKuIk4F3r2kiSOjtLtCS1k4joHxGPRsTVETEzIsZFxMci4v6IeCIihlVuf42If1T+3LHy3C9GxDWV+x+qPL9HCzlbRcQdlX38FIgm646PiL9FxLSI+GlEdKk8Xh8R/xkRf4+IuyJi64gYDQwFxlW2717ZzVmV7WZExE5lfs0kqaOwREtS+/oA8ANgELAT8BkaLk98HvBVGi7Hvm9m7g58HfiPyvO+D3wgIo4EfgH838xc3ELGN4D7Kvu4GXgPQETsDBwNfCQzdwNWAMdVntMT+Htm7gHcA3wjM2+k4XL3x2Xmbpm5pLLty5XtrqiMW5I6va7tPQBJ2sA9lZkzACJiFnBXZmZEzAD6A5sD/x0ROwAJdAPIzJURcRIwHfhpZt6/lox9gU9WnndrRLxSefwAYAgwOSIAugMvVdatBH5duf8/wO/Wsv9V66auypGkzs4SLUnt680m91c2WV5Jw2v0t4CJmXlkRPQHJjXZfgegntado5zNPBbAf2fmV97h81dZNeYV+H1F0gbC0zkkqWPbHHiucv+kVQ9GxOY0nAayL7BV5XzlltxL5TSNiBgFbFl5/C5gdERsU1nXJyLeW1m3EbBqn58B7qvcXwT0Xo/5SFKnYImWpI7tUuA7EXE/0KXJ4/8F/CQzHwf+D3DxqjLcjAuBfSPi78BBwDMAmTkb+BpwR0RMB/4MbFd5zhvAwIiYCuwPfLPy+LXAlWu8sVCSNjiRubbf0EmSNkQRUZ+Zvdp7HJLUUXkkWpIkSSrII9GS1ElExMnA2Ws8fH9mfr49xiNJnZklWpIkSSrI0zkkSZKkgizRkiRJUkGWaEmSJKkgS7QkSZJU0P8PQQivY8xf0CkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.set_index('max_depth').plot(figsize = (12,7))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e80ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
